# ü§ñ SuperCoder

[![Version](https://img.shields.io/badge/version-0.2.3-blue.svg)](https://github.com/Mage212/supercoder)
[![Python](https://img.shields.io/badge/python-3.11+-green.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

**AI Coding Assistant for the Terminal** ‚Äî A powerful, extensible, and terminal-native coding agent designed to help you build, search, and fix code with natural language.

---

## üÜï What's New in v0.2.3

- **Ask Mode**: New `/ask` command for Q&A without file modifications
- **Code Mode**: New `/code` command to switch back to full editing mode
- **Mode-Aware Tools**: Ask mode restricts tools to read-only operations
- **Enhanced Prompts**: Improved tool calling examples with correct parameter names

### Previous: v0.2.2

- **Improved UI**: Enhanced chat interface with styled user/assistant messages
- **Interactive Command Execution**: EOF-based input handling to prevent command hangs
- **Tool Calling Configuration**: Model-specific tool calling instructions

---

## ‚ú® Core Features

### üîç Code Search
Performs complex code searches across your project to quickly locate specific patterns using `git grep` with context-aware output and fallback to standard `grep`.

### üìÅ Project Structure Exploration
Provides an organized, tree-based view of your project's folders and files, intelligently ignoring build artifacts and junk files (`.git`, `node_modules`, etc.).

### ‚úèÔ∏è Intelligent Code Editing
Modifies your codebase seamlessly using diff-based operations. Supported operations include:
- `search_replace`: Precise text replacement.
- `insert_after`/`insert_before`: Contextual code insertion.
- `replace_lines`: Range-based line modification.
- `create`: New file generation.

### üìú Supercoder Rules (Custom rules)
Leverage project-specific rules to guide the agent. Place `.md` files in `.supercoder/rules/` and they will be automatically loaded into the agent's context.

### üó∫Ô∏è RepoMap Support
Uses `tree-sitter` and `networkx` to generate a high-level map of your repository, helping the LLM understand relationships between files and symbols.

### üß† Context Management
- **Token Counter**: Real-time monitoring of context usage.
- **Smart Compaction**: Use `/compact` to summarize conversation history and free up token space without losing key context.

### üíæ Session Persistence
- **Auto-Save**: Your conversation is automatically saved after each message exchange.
- **Resume Sessions**: Use `/continue` to pick up where you left off after closing SuperCoder.
- **Session History**: Up to 10 sessions are stored in `.supercoder/sessions/`.
- **Compact Integration**: When you `/compact`, the session file is also updated with the summary.

---

## üöÄ Getting Started

### Installation

**From GitHub (recommended):**
```bash
pip install git+https://github.com/Mage212/supercoder.git
```

**For development (editable mode):**
```bash
git clone https://github.com/Mage212/supercoder.git
cd supercoder
pip install -e .
```

### Configuration

SuperCoder supports multiple models and endpoints. Configure them via environment variables or a config file.

**Configuration files (in order of priority):**
1. Environment variables (highest priority)
2. `.supercoder.yaml` in your project directory
3. `~/.supercoder/config.yaml` (global config)

**Environment Variables:**
```bash
export SUPERCODER_API_KEY="sk-..."
export SUPERCODER_MODEL="gpt-4o"
export SUPERCODER_BASE_URL="https://api.openai.com/v1"  # Optional
```

**Custom Endpoints (OpenRouter, Ollama, LM Studio, etc.):**
```bash
export SUPERCODER_BASE_URL="https://openrouter.ai/api/v1"
export SUPERCODER_API_KEY="sk-or-..."
export SUPERCODER_MODEL="openai/gpt-4o"
```

**Example `~/.supercoder/config.yaml`:**
```yaml
# Default model profile to use on startup
default_model: "default"

# Model profiles - define multiple LLM configurations
models:
  default:
    api_key: "sk-..."
    endpoint: "https://api.openai.com/v1"
    model: "gpt-4o-mini"
  
  # OpenRouter with Qwen-style model
  openrouter-qwen:
    api_key: "sk-or-v1-..."
    endpoint: "https://openrouter.ai/api/v1"
    model: "openai/gpt-oss-20b:free"
    tool_calling_type: "qwen_like"  # See Tool Calling Types below
  
  # Local Ollama
  ollama:
    api_key: "ollama"
    endpoint: "http://localhost:11434/v1"
    model: "qwen2.5-coder:7b"
    tool_calling_type: "supercoder"

# Shared settings (applied to all models)
temperature: 0.2
max_context_tokens: 32000
request_timeout: 60.0
debug: false
```

### Tool Calling Types

Different models expect tools to be called in different formats. Use `tool_calling_type` to specify the format:

| Type | Format | Best for |
|------|--------|----------|
| `supercoder` (default) | `<@TOOL>{"name": "...", "arguments": {...}}</@TOOL>` | Most instruction-following models |
| `qwen_like` | `to=tool:name {"arg": "value"}` | Qwen, GPT-OSS, DeepResearch models |
| `json_block` | ` ```json {"tool": "...", "arguments": {...}} ``` ` | Models trained on markdown |
| `xml_function` | `<function_call name="...">...</function_call>` | XML-style models |

---

## ‚å®Ô∏è Usage

Launch the interactive REPL:

```bash
supercoder
```

### CLI Options

```bash
supercoder --help
supercoder --model gpt-4o          # Use specific model
supercoder --debug                 # Enable debug mode
supercoder --no-repo-map           # Disable RepoMap
```

### Slash Commands

| Command | Description |
|---------|-------------|
| `/ask` | Switch to Ask mode (Q&A without edits) |
| `/ask <question>` | Ask one question without editing, then return |
| `/code` | Switch to Code mode (full editing) |
| `/help` | Show available commands |
| `/continue` | Resume a previous session |
| `/sessions` | List saved sessions |
| `/tools` | List active tools and their descriptions |
| `/compact` | Summarize history to save context tokens |
| `/stats` | View current token usage and context status |
| `/clear` | Clear conversation history |
| `/config` | Show current active configuration |
| `/models` | List available model profiles |
| `/model <name>` | Switch to a specific model profile |
| `/debug` | Toggle verbose debug logging |
| `/exit` | Exit the application |

---

## üìÅ Project Structure

```text
supercoder/
‚îú‚îÄ‚îÄ agent/          # CoderAgent logic and prompts
‚îú‚îÄ‚îÄ context/        # Token counting, context window, and session management
‚îú‚îÄ‚îÄ llm/            # LLM providers (OpenAI-compatible endpoints)
‚îú‚îÄ‚îÄ repomap/        # Repository mapping logic (tree-sitter)
‚îú‚îÄ‚îÄ tools/          # Core tools (Search, Edit, Structure, Exec)
‚îú‚îÄ‚îÄ rules_loader.py # Supercoder Rules loading logic
‚îú‚îÄ‚îÄ config.py       # Configuration management
‚îú‚îÄ‚îÄ logging.py      # Conversation logging
‚îú‚îÄ‚îÄ repl.py         # Interactive REPL interface
‚îî‚îÄ‚îÄ main.py         # CLI entry point
```

---

## üì¶ Dependencies

**Core:**
- `openai` ‚Äî LLM API client
- `click` ‚Äî CLI framework
- `rich` ‚Äî Beautiful terminal output
- `prompt-toolkit` ‚Äî Interactive input
- `networkx` ‚Äî Graph-based RepoMap
- `tree-sitter-languages` ‚Äî Code parsing for RepoMap
- `tiktoken` ‚Äî Token counting
- `pyyaml` ‚Äî Configuration files

---

## ‚öñÔ∏è License

MIT
